# -*- coding: utf-8 -*-
"""k-means++.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12FZ6AyhvdlMYumLVxMwOC6m8eWYj7q6e

**Cette partie du code consiste à déployer spark sur google colab**
"""

!apt-get install openjdk-8-jdk-headless -qq > /dev/null
!wget -q http://www-eu.apache.org/dist/spark/spark-2.4.4/spark-2.4.4-bin-hadoop2.7.tgz
!tar xf spark-2.4.4-bin-hadoop2.7.tgz
!pip install -q findspark

import os

os.environ["JAVA_HOME"] = "/usr/lib/jvm/java-8-openjdk-amd64"
os.environ["SPARK_HOME"] = "/content/spark-2.4.4-bin-hadoop2.7"

from google.colab import drive

drive.mount('/content/drive/')

import findspark
findspark.init("spark-2.4.4-bin-hadoop2.7")# SPARK_HOME
from pyspark.sql import SparkSession
spark = SparkSession.builder.master("local[*]").getOrCreate()

from pyspark import SparkContext, SparkConf
from math import sqrt
sc=SparkContext.getOrCreate()

"""**`L'algorithme K-means plus plus`**"""

lines=sc.textFile('/content/drive/My Drive/iris_data.txt')

data = lines.map(lambda x: x.split(','))\
.map(lambda x: [float(i) for i in x[:4]] + [x[4]])\
.zipWithIndex()\
.map(lambda x: (x[1], x[0]))

data.take(5)

# Initialisation du premier centroïde
first_center =sc.parallelize(data.takeSample('withoutReplacment',1),7)\
.zipWithIndex()\
.map(lambda x: (x[1],x[0][1][:-1]))

"""**first_center : un RDD qui contient le premier centoide**"""

first_center.collect()

# matching le premier centre et tous les autres points
match = data.cartesian(first_center)
match.cache()
match.take(5)

from math import sqrt
 
def computeDistance(x,y):
    return sqrt(sum([(a - b)**2 for a,b in zip(x,y)]))

dist_1 = match.map(lambda x: (x[0][0],(x[1][0], computeDistance(x[0][1][:-1], x[1]
[1]))))

"""**dist_1 est un RDD qui contient la distance entre le premier centre et tous les autres points**"""

dist_1.take(5)

dist_11=dist_1.map(lambda x: (x[1][1]))

dist_11.take(5)

# on choisit la plus grande distance
max_dist=dist_11.max()

max_dist

# chercher l'index du deuxième centre
second_center_index = dist_1.filter(lambda x: (x[1][1])== max_dist)

second_center_index.collect()

idx=second_center_index.map(lambda x:x[0])
index=idx.max()

second_center_data=data.filter(lambda x: x[0]==index)

second_center_data.collect()

second_center=second_center_data.map(lambda x: (x[0],x[1][:-1]))

"""**second_center: un RDD qui contient le deuxième centre**"""

second_center.collect()



# maintenant on cherche le troisiéme centroide
# on commence par calculer la mi-distance entre nos 2 centroides

match2 = first_center.cartesian(second_center)

distance = match2 .map(lambda x: (x[0][0],(x[1][0], computeDistance(x[0][1][:-1], x[1]
[1]))))

distance.collect()

dist_2=distance.map(lambda x: (x[1][1]))

val=dist_2.max()

valeur=val/2

# 'valeur' represente la mi-distance entre les 2 centoides
# maintenant on va chercher le 3 centre qui est le plus proche du cette valeur

joined_1 = data.cartesian(first_center)
joined_1.cache()

joined_1 .collect()

def computeDistance(x,y):
    return sqrt(sum([(a - b)**2 for a,b in zip(x,y)]))

# rdd contient tous les distances entre le 1er centroide et les autres data

d = joined_1.map(lambda x: (x[0][0],(x[1][0], computeDistance(x[0][1][:-1], x[1]
[1]))))

d.cache()

d.collect()

# pour savoir le point le plus proche du 'valeur' notre mi-distance entre les 2 premiers centroides
# on va calculer la difference entre ces distances et la mi-distance entre les 2 premiers centroides

difference_distance= d.map(lambda x: (x[0], abs(x[1][1]- valeur)))

difference_distance.collect()

difference_distance_val= d.map(lambda x: (abs(x[1][1]- valeur)))

min_val=difference_distance_val.min()

min_val

third_centre_idx=difference_distance.filter(lambda x : x[1]== min_val)

third_centre_idx.collect()

third_centre_val = third_centre_idx.map(lambda x:x[0])

third_centre_val.collect()

third_centre_index = third_centre_val.max()

third_centre_index

third_center_data=data.filter(lambda x: x[0]==third_centre_index)

third_center_data.collect()

third_center=third_center_data.map(lambda x: (x[0],x[1][:-1]))

"""third_center: un RDD qui contient le troiséme centoide"""

third_center.collect()

c= first_center.union(second_center)

centroides=c.union(third_center)

"""**centoides : un RDD qui contient les résultats finaux de l'algorithme K-means plus plus**"""

centroides.collect()